# 🔎 Web Search Engine – Indexing & Retrieval System

This repository implements the **indexing and search backend** of a custom-built web search engine, written in Python. It efficiently constructs a disk-based inverted index using partial indexing, and supports ranked document retrieval using TF-IDF and PageRank.

> 🕷️ **Crawling is handled by a separate, dedicated crawler** built from scratch to handle:
> - Politeness rules and robot exclusion
> - Trap detection and loop prevention
> - Subdomain tracking and content filtering  
>
> 👉 Visit the crawler repo here: [Web Crawler Repository](https://github.com/rbelavadi/spacetime-crawler4py) 

## 📦 Overview

This repository handles:

- Parsing crawled data from `developer.zip`
- Tokenization, stemming, and stopword filtering
- Partial inverted index creation and memory-efficient merging
- TF-IDF and PageRank scoring
- Boolean and ranked search queries
- Support for boosting based on HTML structure (e.g., titles, headers, bold text)
- Optional support for n-grams, word positions, and anchor text indexing

---

## 🗂️ Directory Structure

web-search-engine/
├── src/ # All source code and modules
├── index/ # (Ignored) Generated indexes after running the pipeline
├── developer.zip # Crawled data archive (not included in repo)
├── README.md
└── .gitignore

## ⚙️ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/rbelavadi/web-search-engine.git
cd web-search-engine
```

### 2. Download the Dataset

The dataset used is developer.zip — a zip archive of ~38,000 HTML pages collected from ics.uci.edu and related UCI subdomains.

These pages were crawled using a custom-built crawler (see Web Crawler Repository) and include faculty profiles, research pages, and course descriptions.

🔗 Download here: [Google Drive](https://drive.google.com/file/d/14zgBWE3lDufPLU1pPrYYG7jOFoISiCMG/view?usp=drive_link) link to developer.zip
📁 Place the file in the root folder of the project.

### 3. Build the Index

This step parses the HTML documents, tokenizes them, and builds a TF-IDF–weighted inverted index.

```bash
python src/buildindex.py
```

### 4. Run the Search Engine

This launches a console-based query interface that supports ranked and Boolean search.

```bash
python src/startMyEngine.py
```

📌 Notes
The index/ folder is ignored via .gitignore and will be regenerated when main.py is run.

developer.zip must be added manually; it contains HTML pages generated by the custom crawler.

The web crawler is a separate project and includes advanced crawling features.
You can find it here: [Web Crawler Repository](https://github.com/rbelavadi/spacetime-crawler4py)

👩‍💻 Author
Ranjani Belavadi
CS & BIM @ UC Irvine
Python | Systems | Information Retrieval

[GitHub](https://github.com/rbelavadi)
